{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutharimanikanta/-technity-tasks-/blob/main/sequence_to_sequence_(seq2seq)_model_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "GVBE-nKbYX_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*A Gated Recurrent Unit (GRU) layer is a type of recurrent neural network (RNN) layer used for processing sequential data, such as text, time series, and audio. It is designed to address some of the limitations of traditional RNNs, particularly regarding the vanishing gradient problem and the difficulty in capturing long-range dependencies in sequences.\n",
        "\n",
        "* i want use Transformer Encoder Layers"
      ],
      "metadata": {
        "id": "qfdsVedChyLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bi-directional RNNs:\n",
        "Purpose: Bi-directional RNNs process sequences in both forward and backward directions.\n",
        "Strengths:\n",
        "Capture context from both past and future tokens.\n",
        "Useful for tasks like part-of-speech tagging, named entity recognition, and sentiment analysis.\n",
        "Handle sequential dependencies well.\n",
        "Weaknesses:\n",
        "Computationally expensive due to bidirectional processing.\n",
        "Still suffer from vanishing gradient problems.\n",
        "Example: Bidirectional LSTMs or GRUs.\n",
        "* Transformer Networks:\n",
        "Purpose: Transformers revolutionized NLP by introducing self-attention mechanisms.\n",
        "Strengths:\n",
        "Parallelizable, making them faster than RNNs.\n",
        "Capture global context effectively.\n",
        "State-of-the-art performance on various NLP benchmarks.\n",
        "Weaknesses:\n",
        "Require large amounts of data and computational resources.\n",
        "Lack inherent sequential processing (no recurrence).\n",
        "Example: BERT, GPT, and other transformer-based models.\n",
        "When to Choose:\n",
        "\n",
        "Bi-directional RNNs: Use when you need fine-grained sequential context and have limited data.\n",
        "Transformers: Opt for transformers when you have abundant data, want to handle long-range dependencies, and aim for top-tier performance."
      ],
      "metadata": {
        "id": "8ANsFfZ-q7e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size=1000, embedding_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(self.vocab_size, self.embedding_size)\n",
        "        self.gru = tf.keras.layers.GRU(self.embedding_size, return_sequences=True, return_state=True)\n",
        "        self.bi = tf.keras.layers.Bidirectional(self.gru)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        words = inputs\n",
        "        embeddings = self.embedding_layer(words)\n",
        "        output_sequence, forward_state, backward_state = self.bi(embeddings)\n",
        "        return output_sequence, forward_state\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, words=20, embedding_size=128):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.words = words\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        self.W1 = self.add_weight(shape=(self.embedding_size, 1), initializer=\"random_uniform\")\n",
        "        self.W2 = self.add_weight(shape=(self.embedding_size, self.words), initializer=\"random_uniform\")\n",
        "        self.W3 = self.add_weight(shape=(self.words, self.embedding_size), initializer=\"random_uniform\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, value = inputs\n",
        "        regressed_query = tf.einsum(\"bij,jk->bik\", query, tf.transpose(self.W1))\n",
        "        regressed_value = tf.einsum(\"bij,jk->bik\", value, self.W2)\n",
        "        sum_query_value = tf.einsum(\"bij,bik->bjk\", regressed_query, regressed_value)\n",
        "        sum_of_query_value = tf.nn.tanh(sum_query_value)\n",
        "        a = tf.einsum(\"bij,ij->bi\", sum_of_query_value, self.W3)\n",
        "        a = tf.nn.softmax(a)\n",
        "        context = tf.einsum(\"bij,bi->bj\", value, a)\n",
        "        return context\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_size=128, vocab_size=1000, words=20):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.words = words\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        self.attention = BahdanauAttention(words=self.words, embedding_size=self.embedding_size)\n",
        "        self.gru = tf.keras.layers.GRU(self.embedding_size, return_sequences=True, return_state=True)\n",
        "        self.op1 = tf.keras.layers.Dense(self.embedding_size * 10, activation='tanh')\n",
        "        self.op2 = tf.keras.layers.Dense(self.embedding_size * 10, activation='tanh')\n",
        "        self.op3 = tf.keras.layers.Dense(self.vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y, state, encode = inputs\n",
        "        context = self.attention((tf.expand_dims(state,axis=1),encode))\n",
        "        state_expanded = tf.expand_dims(state, axis=1)\n",
        "        context_expanded = tf.expand_dims(context, axis=1)\n",
        "        y_expanded = tf.expand_dims(y, axis=1)\n",
        "        gru_input = tf.concat([state_expanded, context_expanded], axis=-1)\n",
        "        gru_input = tf.concat([gru_input, y_expanded], axis=-1)\n",
        "        new_state = self.gru(gru_input)\n",
        "        g_input = tf.concat([tf.concat([y, context], axis=-1), new_state[0]], axis=-1)\n",
        "        g_output = self.op3(self.op2(self.op1(g_input)))\n",
        "        return g_output, new_state[0]\n"
      ],
      "metadata": {
        "id": "4bJpoUeVdUns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "class EnglishToTeluguTranslator:\n",
        "    def __init__(self, encoder_input_words=20, english_vocab_size=1000, telugu_vocab_size=1000, embedding_size=128,\n",
        "                 epochs=30, batch_size=200, optimizer='adam'):\n",
        "        self.encoder_input_words = encoder_input_words\n",
        "        self.english_vocab_size = english_vocab_size\n",
        "        self.telugu_vocab_size = telugu_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_fn = CategoricalCrossentropy(from_logits=True)\n",
        "        self.loss_history = []\n",
        "        self.encoder = Encoder(vocab_size=english_vocab_size, embedding_size=embedding_size)\n",
        "        self.decoder = None\n",
        "\n",
        "    def get_enc_dec(self):\n",
        "        x_encoder_input = tf.keras.layers.Input(self.encoder_input_words)\n",
        "        encode = Encoder(vocab_size=self.english_vocab_size, embedding_size=self.embedding_size)(x_encoder_input)\n",
        "        self.encoder = tf.keras.Model(inputs=x_encoder_input, outputs=encode)\n",
        "\n",
        "        x_decoder_input = tf.keras.layers.Input(1)\n",
        "        x_decoder = Embedding(self.telugu_vocab_size, self.embedding_size)(x_decoder_input)\n",
        "        x_state_input = tf.keras.layers.Input(self.embedding_size)\n",
        "        x_states_input = tf.keras.layers.Input((self.encoder_input_words, self.embedding_size))\n",
        "\n",
        "        decode = Decoder(embedding_size=self.embedding_size, vocab_size=self.telugu_vocab_size,\n",
        "                         words=self.encoder_input_words)((x_decoder[:, 0], x_state_input, x_states_input))\n",
        "        self.decoder = tf.keras.Model(inputs=[x_decoder_input, x_state_input, x_states_input], outputs=decode)\n",
        "        return self.encoder.summary(), self.decoder.summary()\n",
        "\n",
        "    def train_translator(self, X_english, X_telugu):\n",
        "        optimizer = tf.keras.optimizers.Adam()\n",
        "        loss_fn = self.loss_fn\n",
        "\n",
        "        epochs, batch_size = self.epochs, self.batch_size\n",
        "        total_instances = len(X_english)\n",
        "\n",
        "        self.loss_history = []\n",
        "\n",
        "        # Initialize encoder and decoder models\n",
        "        self.get_enc_dec()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            batch_loss = tf.constant(0.0)\n",
        "            for batch in tqdm(range(0, total_instances, batch_size)):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    loss_count = tf.constant(0.0)\n",
        "                    x1_train = X_english[batch:batch + batch_size]\n",
        "                    x2_train = X_telugu[batch:batch + batch_size]\n",
        "\n",
        "                    H, state = self.encoder(x1_train)\n",
        "\n",
        "                    for query_number in range(x2_train.shape[-1]):\n",
        "                        output, state = self.decoder((x2_train[:, query_number], state, H))\n",
        "                        loss_count = loss_count + loss_fn(x2_train[:, query_number], output)\n",
        "\n",
        "                grads = tape.gradient(loss_count, self.encoder.trainable_weights + self.decoder.trainable_weights)\n",
        "                optimizer.apply_gradients(zip(grads, self.encoder.trainable_weights + self.decoder.trainable_weights))\n",
        "                batch_loss = batch_loss + loss_count\n",
        "\n",
        "            print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(epochs) + \" : Error \" + str(batch_loss.numpy()))\n",
        "            self.loss_history.append(batch_loss.numpy())\n",
        "\n",
        "    def translate_sentence(self, english_sentence):\n",
        "        # Assuming you have a tokenizer initialized and fit on your English text data\n",
        "        # english_indices = your_tokenizer.texts_to_sequences([english_sentence])[0]\n",
        "        # english_indices = np.array([english_indices])\n",
        "\n",
        "        english_indices = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])  # Example input, replace with actual indices\n",
        "\n",
        "        H, state = self.encoder(english_indices)\n",
        "\n",
        "        telugu_sentence = []\n",
        "\n",
        "        start_token = np.array([2])  # Replace 2 with the actual index of the start token in the Telugu vocabulary\n",
        "        start_token = tf.expand_dims(start_token, axis=0)\n",
        "\n",
        "        for _ in range(10):  # Replace 10 with the actual maximum length of the Telugu sentence you want to generate\n",
        "            output, state = self.decoder((start_token, state, H))\n",
        "            predicted_word_index = np.argmax(output.numpy(), axis=-1)\n",
        "            telugu_sentence.append(predicted_word_index[0][0])\n",
        "\n",
        "            if predicted_word_index[0][0] == 3:  # Replace 3 with the actual index of the end token in the Telugu vocabulary\n",
        "                break\n",
        "\n",
        "            start_token = predicted_word_index\n",
        "\n",
        "        return telugu_sentence"
      ],
      "metadata": {
        "id": "XWDR5EXa23Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Luong Attention (Scaled Dot-Product Attention):\n",
        "* Self-Attention (Scaled Dot-Product Attention):"
      ],
      "metadata": {
        "id": "zqFb0bkmjxfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Parse the Excel data\n",
        "data = pd.read_excel('/content/engtotel.xlsx')\n",
        "\n",
        "# Drop any rows with NaN values\n",
        "data = data.dropna()\n",
        "\n",
        "english_sentences = data['english'].astype(str).tolist()\n",
        "telugu_sentences = data['telugu'].astype(str).tolist()\n",
        "\n",
        "# Step 2: Tokenization\n",
        "english_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "telugu_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "english_tokenizer.fit_on_texts(english_sentences)\n",
        "telugu_tokenizer.fit_on_texts(telugu_sentences)\n",
        "\n",
        "english_sequences = english_tokenizer.texts_to_sequences(english_sentences)\n",
        "telugu_sequences = telugu_tokenizer.texts_to_sequences(telugu_sentences)\n",
        "\n",
        "# Step 3: Padding\n",
        "max_length = max(max(len(seq) for seq in english_sequences), max(len(seq) for seq in telugu_sequences))\n",
        "english_sequences_padded = tf.keras.preprocessing.sequence.pad_sequences(english_sequences, maxlen=max_length, padding='post')\n",
        "telugu_sequences_padded = tf.keras.preprocessing.sequence.pad_sequences(telugu_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Step 4: Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(english_sequences_padded, telugu_sequences_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Model Training\n",
        "translator = EnglishToTeluguTranslator()\n",
        "translator.train_translator(X_train, y_train)\n",
        "\n",
        "# Step 6: Evaluation (Optional)\n",
        "# Evaluate your model's performance on the validation set using metrics like BLEU score or simply by inspecting translations manually.\n",
        "\n",
        "# Step 7: Inference\n",
        "english_sentence = \"His legs are long.\"\n",
        "english_sequence = english_tokenizer.texts_to_sequences([english_sentence])\n",
        "translated_sequence = translator.translate_sentence(english_sequence)\n",
        "translated_sentence = telugu_tokenizer.sequences_to_texts([translated_sequence])[0]\n",
        "print(\"Translated Sentence:\", translated_sentence)\n"
      ],
      "metadata": {
        "id": "ZOiyYfF0jxJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "292e3cac-23e0-4e9e-ef99-0e3655ccad26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"decoder\" (type Decoder).\n\nin user code:\n\n    File \"<ipython-input-6-d2351eb279d2>\", line 60, in call  *\n        context = self.attention((tf.expand_dims(state,axis=1),encode))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filetatr33tl.py\", line 11, in tf__call\n        regressed_query = ag__.converted_call(ag__.ld(tf).einsum, ('bij,jk->bik', ag__.ld(query), ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(self).W1,), None, fscope)), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'bahdanau_attention' (type BahdanauAttention).\n    \n    in user code:\n    \n        File \"<ipython-input-6-d2351eb279d2>\", line 34, in call  *\n            regressed_query = tf.einsum(\"bij,jk->bik\", query, tf.transpose(self.W1))\n    \n        ValueError: Dimensions must be equal, but are 128 and 1 for '{{node decoder/bahdanau_attention/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"bij,jk->bik\"](decoder/ExpandDims, decoder/bahdanau_attention/transpose)' with input shapes: [?,1,128], [1,128].\n    \n    \n    Call arguments received by layer 'bahdanau_attention' (type BahdanauAttention):\n      • inputs=('tf.Tensor(shape=(None, 1, 128), dtype=float32)', 'tf.Tensor(shape=(None, 20, 128), dtype=float32)')\n\n\nCall arguments received by layer \"decoder\" (type Decoder):\n  • inputs=('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 20, 128), dtype=float32)')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3fab68d9d1a1>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Step 5: Model Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnglishToTeluguTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Step 6: Evaluation (Optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f75eb7b61828>\u001b[0m in \u001b[0;36mtrain_translator\u001b[0;34m(self, X_english, X_telugu)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Initialize encoder and decoder models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enc_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f75eb7b61828>\u001b[0m in \u001b[0;36mget_enc_dec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx_states_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_input_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         decode = Decoder(embedding_size=self.embedding_size, vocab_size=self.telugu_vocab_size,\n\u001b[0m\u001b[1;32m     31\u001b[0m                          words=self.encoder_input_words)((x_decoder[:, 0], x_state_input, x_states_input))\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_decoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_state_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_states_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file7s4fblyc.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mstate_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mcontext_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filetatr33tl.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mregressed_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bij,jk->bik'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mregressed_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bij,jk->bik'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0msum_query_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bij,bik->bjk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressed_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressed_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"decoder\" (type Decoder).\n\nin user code:\n\n    File \"<ipython-input-6-d2351eb279d2>\", line 60, in call  *\n        context = self.attention((tf.expand_dims(state,axis=1),encode))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filetatr33tl.py\", line 11, in tf__call\n        regressed_query = ag__.converted_call(ag__.ld(tf).einsum, ('bij,jk->bik', ag__.ld(query), ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(self).W1,), None, fscope)), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'bahdanau_attention' (type BahdanauAttention).\n    \n    in user code:\n    \n        File \"<ipython-input-6-d2351eb279d2>\", line 34, in call  *\n            regressed_query = tf.einsum(\"bij,jk->bik\", query, tf.transpose(self.W1))\n    \n        ValueError: Dimensions must be equal, but are 128 and 1 for '{{node decoder/bahdanau_attention/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"bij,jk->bik\"](decoder/ExpandDims, decoder/bahdanau_attention/transpose)' with input shapes: [?,1,128], [1,128].\n    \n    \n    Call arguments received by layer 'bahdanau_attention' (type BahdanauAttention):\n      • inputs=('tf.Tensor(shape=(None, 1, 128), dtype=float32)', 'tf.Tensor(shape=(None, 20, 128), dtype=float32)')\n\n\nCall arguments received by layer \"decoder\" (type Decoder):\n  • inputs=('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 20, 128), dtype=float32)')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9CbpihhPOJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAtX-BOTWQen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}